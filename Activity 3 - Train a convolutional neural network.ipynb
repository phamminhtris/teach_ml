{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from PIL import Image\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28)\n",
      "Training labels shape:  (60000,)\n",
      "Test data shape:  (10000, 28, 28)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"Training data shape: \", x_train.shape)\n",
    "print(\"Training labels shape: \", y_train.shape)\n",
    "print(\"Test data shape: \", x_test.shape)\n",
    "print(\"Test labels shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28, 1)\n",
      "Training labels shape:  (60000, 10)\n",
      "Test data shape:  (10000, 28, 28, 1)\n",
      "Test labels shape:  (10000, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Define some variables \n",
    "img_rows, img_cols = 28, 28            # input image dimensions\n",
    "num_classes = 10                       # 10 classes\n",
    "input_shape = (img_rows, img_cols, 1)  # shape = (height, width, channels)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"Training data shape: \", x_train.shape)\n",
    "print(\"Training labels shape: \", y_train.shape)\n",
    "print(\"Test data shape: \", x_test.shape)\n",
    "print(\"Test labels shape: \", y_test.shape)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 12\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint('MNIST_ConvNet.h5', monitor='val_acc', verbose=1, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.2729 - acc: 0.9168 - val_loss: 0.0749 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97650, saving model to MNIST_ConvNet.h5\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0937 - acc: 0.9720 - val_loss: 0.0440 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.97650 to 0.98460, saving model to MNIST_ConvNet.h5\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0702 - acc: 0.9789 - val_loss: 0.0344 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.98460 to 0.98900, saving model to MNIST_ConvNet.h5\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0569 - acc: 0.9829 - val_loss: 0.0323 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98900\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0484 - acc: 0.9859 - val_loss: 0.0281 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.98900 to 0.98990, saving model to MNIST_ConvNet.h5\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0441 - acc: 0.9867 - val_loss: 0.0285 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98990\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0389 - acc: 0.9880 - val_loss: 0.0284 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.98990 to 0.99040, saving model to MNIST_ConvNet.h5\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0343 - acc: 0.9890 - val_loss: 0.0296 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.99040 to 0.99060, saving model to MNIST_ConvNet.h5\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0348 - acc: 0.9894 - val_loss: 0.0254 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.99060 to 0.99160, saving model to MNIST_ConvNet.h5\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0305 - acc: 0.9910 - val_loss: 0.0261 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99160\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0290 - acc: 0.9909 - val_loss: 0.0270 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99160\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0281 - acc: 0.9913 - val_loss: 0.0263 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10ff5e358>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('MNIST_ConvNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('MNIST_ConvNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.025350918095318774\n",
      "Test accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image_label: 7\n",
      "Predicted Label:  7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1439a2630>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Test_image_number = 41\n",
    "\n",
    "print(\"Image_label:\", y_test[Test_image_number].argmax())\n",
    "print(\"Predicted Label: \", model.predict(x_test[Test_image_number].reshape(1,28,28,1)).argmax())\n",
    "plt.figure(figsize = (1,1))\n",
    "plt.imshow(x_test[Test_image_number].reshape(28,28), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABAhJREFUeJztnD+oHFUUh7+fMVZaRITw0PgHsY8gNtoKYmNsgikkVs8moNgoqSwt1FZ4YjpBhAimkxQWVpJnCMYkPA2imPAUJIV/GtH8LHZWNpvdndnd2bNz550Pht29u3Pn8r3zzpwZ7lzZJonhjnUPYC+RsgNJ2YGk7EBSdiApO5CUHchSsiU9K2lH0lVJb7Y1qL6iRS9qJO0DvgOeAa4B54Bjti+3N7x+cecS+z4JXLX9A4Ckj4HngamyJfX2ctW26n6zTBq5H/h55PO1qu0WJG1K2pa0vcSxesEykd0I21vAFvQ7spuwTGRfBw6NfH6gakumsIzsc8Bjkh6RdBfwInCmnWE1w/YtW9dZOI3Y/kfSCeBzYB9wyval1kbWQxYu/RY6WEs5u8mYpdrioFVWXY0kc7LyaqRN5vkvHP42OsJnkZEdSBGRXRfR49E7+vsuRXhGdiBFy5Y0MWIntXWhFi9admmk7EBSdiB7TvY6c/eek71OipA9reqYFaXT9lknRcjuCyk7kJQdSBH3RoYMc/B4nh7/LGntV4uTyMgOpEjZdZVGk6heR71dpOxSKVp2F2vpWRQte0gp0nshuxSKKv3qWPakuWoysgPpVWRPYtaNqmgysgNJ2YGk7EB6m7O7UH2MUxvZkg5J+kLSZUmXJL1atd8r6ayk76vXA6sfbtnUThmWtAFs2D4v6R7ga+AI8DJww/bb1WN5B2y/UdNXWLhFVyFNpgzfNnu/bgM+Y/A43g6DPwLABrDTYF9HbdNY4fFq3c2VsyU9DDwOfAUctL1bffULcHCevlbJpKjuwr2TxrIl3Q2cBl6z/fvo4G17WoqQtAlsLjvQXtAwdexn8OzM6yNtnUkjs1jVMSeModZjk2pEwIfAFdvvjXx1BjhevT/OIJcnM2hSjTwNfAlcBG5WzScZ5O1PgAeBn4Cjtm/U9NVqNTJr7F18gKnIp8WGlCa76Mv1eSbDd4GiZZdGL+6NdDWSx8nIDiRlB5KyA0nZgaTsQFJ2ICk7kOg6+zfgr+q1VO7j9vE/1GTH0HsjAJK2bT8RetAWWWb8mUYCSdmBrEP21hqO2SYLjz88Z+9lMo0EEia7xLW2Z8wGe0vSdUkXqu25Rv1FpJFS19qeMRvsKPCn7Xfm6S8qsv9fa9v238Bwre1OY3vX9vnq/R/AFSYsW92UKNmN1truMmOzwQBOSPpG0qmmk0rzBNmA8dlgwPvAo8BhYBd4t0k/UbKLXWtb0n4Goj+y/SmA7V9t/2v7JvABgzRZS5Tsta+1vQjTZoNVJ84hLwDfNukv5K6fy11r+yngJeCipAtV20ngmKTDDOb5/Qi80qSzvIIMJE+QgaTsQFJ2ICk7kJQdSMoOJGUHkrID+Q/0hqaABIqzsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gimp_image = np.array(Image.open('gimp_image.png'))\n",
    "plt.figure( figsize = (1,1))\n",
    "plt.imshow(gimp_image, cmap = 'gray')\n",
    "print(\"Predicted Label: \", model.predict(gimp_image.reshape(1,28,28,1)/255).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
