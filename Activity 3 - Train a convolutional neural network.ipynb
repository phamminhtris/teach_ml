{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from PIL import Image\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28)\n",
      "Training labels shape:  (60000,)\n",
      "Test data shape:  (10000, 28, 28)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"Training data shape: \", x_train.shape)\n",
    "print(\"Training labels shape: \", y_train.shape)\n",
    "print(\"Test data shape: \", x_test.shape)\n",
    "print(\"Test labels shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28, 1)\n",
      "Training labels shape:  (60000, 10)\n",
      "Test data shape:  (10000, 28, 28, 1)\n",
      "Test labels shape:  (10000, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Define some variables \n",
    "img_rows, img_cols = 28, 28            # input image dimensions\n",
    "num_classes = 10                       # 10 classes\n",
    "input_shape = (img_rows, img_cols, 1)  # shape = (height, width, channels)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"Training data shape: \", x_train.shape)\n",
    "print(\"Training labels shape: \", y_train.shape)\n",
    "print(\"Test data shape: \", x_test.shape)\n",
    "print(\"Test labels shape: \", y_test.shape)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint('MNIST_ConvNet.h5', monitor='val_acc', verbose=1, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.2637 - acc: 0.9191 - val_loss: 0.0533 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.98350, saving model to MNIST_ConvNet.h5\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0887 - acc: 0.9739 - val_loss: 0.0396 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.98350 to 0.98700, saving model to MNIST_ConvNet.h5\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0673 - acc: 0.9805 - val_loss: 0.0361 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.98700 to 0.98860, saving model to MNIST_ConvNet.h5\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0561 - acc: 0.9832 - val_loss: 0.0332 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98860\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 90s 2ms/step - loss: 0.0473 - acc: 0.9859 - val_loss: 0.0317 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.98860 to 0.98990, saving model to MNIST_ConvNet.h5\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0416 - acc: 0.9872 - val_loss: 0.0285 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.98990 to 0.99080, saving model to MNIST_ConvNet.h5\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0372 - acc: 0.9882 - val_loss: 0.0269 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.99080 to 0.99160, saving model to MNIST_ConvNet.h5\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0359 - acc: 0.9893 - val_loss: 0.0264 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.99160 to 0.99200, saving model to MNIST_ConvNet.h5\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0327 - acc: 0.9904 - val_loss: 0.0295 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99200\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 89s 1ms/step - loss: 0.0303 - acc: 0.9901 - val_loss: 0.0283 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99200\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0299 - acc: 0.9907 - val_loss: 0.0269 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99200\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 90s 1ms/step - loss: 0.0285 - acc: 0.9915 - val_loss: 0.0270 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x134ca3908>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('MNIST_ConvNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('MNIST_ConvNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.026377914569733547\n",
      "Test accuracy: 0.992\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image_label: 7\n",
      "Predicted Label:  7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x137a7cfd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Test_image_number = 41\n",
    "\n",
    "print(\"Image_label:\", y_test[Test_image_number].argmax())\n",
    "print(\"Predicted Label: \", model.predict(x_test[Test_image_number].reshape(1,28,28,1)).argmax())\n",
    "plt.figure(figsize = (1,1))\n",
    "plt.imshow(x_test[Test_image_number].reshape(28,28), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAECUlEQVR4nO2cPagcVRTHf3+jVrGICOGh8QOxjyA22gpiY7QIppBYPZuAdkoqSwu1FZ6YThAhgukkhYWV5BmCMQlPgygmPCMSxY9GNH+LnZWXzc7svP04s3f2/GDYnTt77z375+yZM7NnrmyTLJbbujZgFUiRA0iRA0iRA0iRA0iRA5hJZElPS9qSdFnS6/Myqm9o2jxZ0h7gG+Ap4ApwBjhi++L8zOsHt8/Q93Hgsu3vACR9CDwL1IosqbdXPrZVd2yWcHEv8OOO/StV201IWpe0KWlzhrmKZhZPboXtDWAD+u3JTcziyVeBAzv276vakhFmEfkM8IikhyTdCbwAnJqPWe2wfdO2rEwdLmz/I+kY8CmwBzhh+8LcLOsRU6dwU002p5jcxmap9mS/EBaVXSQtWXh2MU9286sbfjbao8eRnhxAEZ48yYNHvXXn55fBo9OTAyhaZEljPXRcW5e5dNEil0KKHECKHMDKidxFbF45kbugCJHrsogmr6zr0wVFiFw6KXIAKXIARdy7GDKMsaNxeHRf0lL9U5KeHECRIk/KHNp4cWS+XKTIpVG0yMuUCzdRtMhDll3sXoi87BSVwk1i1pPhokhPDqBXnjyOphtIUaQnB5AiB5AiB9DbmJw3iFaMiSJLOiDpM0kXJV2Q9ErVfrek05K+rV73Ld7c2eni6nBifbKkNWDN9llJdwFfAoeAl4Drtt+snuHbZ/u1CWOF/YajU7em+uRbHgmYtAGfMHh2b4uB+ABrwFaLvo7YxhEwZ+333tWJT9KDwKPAF8B+29vVoZ+A/TV91oH13czTO3bhwXsZhIrnq/3fRo7/2pUnN7GoOcfYUPu9W2UXku4ATgIf2P64ar5Wxeth3P65zVirSJvsQsD7wCXb7+w4dAo4Wr0/yiBWh1JKcUub7OJJ4HPgPHCjaj7OIC5/BNwP/AActn19wlhzzS6abF+mp5+KfMRslNHv0IUHN4mcV3wB9OLexbLE3jrSkwNIkQNIkQNIkQNIkQNIkQNIkQOIzpN/Af6qXkvlHm61/4GmDqGX1QCSNm0/FjrpHJnG/gwXAaTIAXQh8kYHc86TXdsfHpNXkQwXAaTIAYSJXOKC1g3VU29IuirpXLU90zhOREwudUHrhuqpw8Cftt9qM06UJ/+/oLXtv4HhgtZLje1t22er938AlxizRvQkokRutaD1MjNSPQVwTNJXkk5MKrbME18LJO1lUNzzqu3fgXeBh4GDwDbwdlP/KJGLXdB6XPWU7Wu2/7V9A3iPQTisJUrkzhe0noa66qlheVrFc8DXTeOE3Op0uQtaPwG8CJyXdK5qOw4ckXSQQbHh98DLTYPkZXUAeeILIEUOIEUOIEUOIEUOIEUOIEUO4D865Z1sHO5UtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gimp_image = np.array(Image.open('gimp_image.png'))\n",
    "plt.figure( figsize = (1,1))\n",
    "plt.imshow(gimp_image, cmap = 'gray')\n",
    "print(\"Predicted Label: \", model.predict(gimp_image.reshape(1,28,28,1)/255).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
